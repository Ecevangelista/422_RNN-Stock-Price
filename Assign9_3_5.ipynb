{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign9_3_5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxmeEYOn49kMiTJx/RvChk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ecevangelista/422_RNN-Stock-Price/blob/main/Assign9_3_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayxdTj-zaddN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingest"
      ],
      "metadata": {
        "id": "u9dMvDSiapov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "id": "pNWeraR2ar4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "from os import listdir\n",
        "import yfinance as yf\n",
        "from shutil import copyfile\n",
        "import numpy as np\n",
        "from numpy import arange, asarray, save, load\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "import math\n",
        "from matplotlib.image import imread\n",
        "from random import seed\n",
        "from random import random\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, Conv1D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense, LSTM, SimpleRNN\n",
        "from keras.layers import Flatten, Dropout, TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.metrics import MeanSquaredError"
      ],
      "metadata": {
        "id": "7M2pVadxasAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download s&p500 index data for 5 years, 2015 - 2019\n",
        "\n",
        "gspc = yf.Ticker(\"^GSPC\")\n",
        "#print(gspc)\n",
        "\n",
        "datagspc = gspc.history(start = \"2015-01-01\", end=\"2019-12-31\")"
      ],
      "metadata": {
        "id": "GHpI2vEZawt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "yTXcDbz2a6Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagspc.sample(10)"
      ],
      "metadata": {
        "id": "vLAmPGY9axRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagspc.describe()"
      ],
      "metadata": {
        "id": "VBOK_dB2axXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(datagspc)"
      ],
      "metadata": {
        "id": "77SmNMzZbAog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataclose = datagspc[['Close']]"
      ],
      "metadata": {
        "id": "Dl785OJkbGrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking the Closing prices to look at trends over the 5 years:\n",
        "There is a slight dip between 2015 - 2016 and in early 2019. Closing prices \n",
        "have seen an increase over the past 5 years otherwise. The data will be split into allocating the 1st 3 years (2015-2017) to the Train set, 2018 to Validation, and 2019 to Test. 2018 has a high degree of volatility vs. the earlier years, so this will affect model fitting.  "
      ],
      "metadata": {
        "id": "wTXNNFysbS2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot dataclose\n",
        "\n",
        "plt.plot(dataclose)\n",
        "plt.title(\"Closing Prices S&P Index 2015 - 2019\")\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "5wz32_YVbM_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "bC5eip4Ib73W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert pandas df to values to prepare for keras\n",
        "\n",
        "datasetf = dataclose.values\n",
        "datasetf = datasetf.astype('float32')"
      ],
      "metadata": {
        "id": "sL8Bh_Azb-Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "datasetf = scaler.fit_transform(datasetf)"
      ],
      "metadata": {
        "id": "YkFH3w-ccTy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# split into samples\n",
        "X_samples = list()\n",
        "y_samples = list()\n",
        " \n",
        "NumerOfRows = len(datasetf)\n",
        "TimeSteps=5  # next day's Price Prediction is based on past 5 days' prices\n",
        " \n",
        "# Iterate thru the values to create combinations\n",
        "for i in range(TimeSteps , NumerOfRows , 1):\n",
        "    x_sample = datasetf[i-TimeSteps:i]\n",
        "    y_sample = datasetf[i]\n",
        "    X_samples.append(x_sample)\n",
        "    y_samples.append(y_sample)\n",
        " \n",
        "################################################\n",
        "# Reshape the Input as a 3D (number of samples, Time Steps, Features)\n",
        "X_data=np.array(X_samples)\n",
        "X_data=X_data.reshape(X_data.shape[0],X_data.shape[1], 1)\n",
        "print('\\n#### Input Data shape ####')\n",
        "print(X_data.shape)\n",
        " \n",
        "# We do not reshape y as a 3D data  as it is supposed to be a single column only\n",
        "y_data=np.array(y_samples)\n",
        "y_data=y_data.reshape(y_data.shape[0], 1)\n",
        "print('\\n#### Output Data shape ####')\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "id": "MJKXHEdIcT6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is split into 60% Train, 20% Validation, 20% Test."
      ],
      "metadata": {
        "id": "-yo0MBr2cjqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train and test\n",
        "X_train=X_data[:752]\n",
        "X_valid = X_data[752:1002]\n",
        "X_test=X_data[1002:]\n",
        "y_train=y_data[:752]\n",
        "y_valid = y_data[752:1002]\n",
        "y_test=y_data[1002:]\n",
        " \n",
        "############################################\n",
        " \n",
        "# Printing the shape of training and testing\n",
        "print('\\n#### Training Data shape ####')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('\\n#### Valid Data shape ####')\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print('\\n#### Testing Data shape ####')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "-DP-Hdd5cdQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model - Keras Linear regression"
      ],
      "metadata": {
        "id": "7_ynYmZFcvmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = Sequential([\n",
        "    keras.layers.Flatten(input_shape=[5,1]),\n",
        "    keras.layers.Dense(1)                                      \n",
        "])\n",
        "\n",
        "base_model.compile(optimizer='adam', loss='MeanSquaredError')\n",
        "history = base_model.fit(X_train, y_train, epochs = 10, batch_size = 1, verbose =2)"
      ],
      "metadata": {
        "id": "SjHs2hzoc213"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "trainPredict = base_model.predict(X_train)\n",
        "validPredict = base_model.predict(X_valid)\n",
        "testPredict = base_model.predict(X_test)\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainYbase = scaler.inverse_transform(y_train)\n",
        "\n",
        "validPredict = scaler.inverse_transform(validPredict)\n",
        "validYbase = scaler.inverse_transform(y_valid)\n",
        "\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testYbase = scaler.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "ZjBeJZfndC4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BASELINE RMSE\n",
        "\n",
        "trainrmsebase = mean_squared_error(trainYbase, trainPredict[:,0], squared = False)\n",
        "validrmsebase = mean_squared_error(validYbase, validPredict[:,0], squared = False)\n",
        "testrmsebase = mean_squared_error(testYbase, testPredict[:,0], squared = False)\n",
        "\n",
        "print(\"Train RMSE Base\", trainrmsebase)\n",
        "print(\"Valid RMSE Base\", validrmsebase)\n",
        "print(\"Test RMSE Base\", testrmsebase)\n"
      ],
      "metadata": {
        "id": "dzp3vvcAdC8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_12gLXujdTh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep RNN Model"
      ],
      "metadata": {
        "id": "_NamWpHHda2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepmodel = Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences = True, input_shape = [None,1]),\n",
        "    keras.layers.SimpleRNN(20),\n",
        "    keras.layers.Dense(1)                                      \n",
        "])\n",
        "\n",
        "deepmodel.compile(optimizer='adam', loss='MeanSquaredError')\n",
        "history = deepmodel.fit(X_train, y_train, epochs = 10, batch_size = 1, verbose =2)"
      ],
      "metadata": {
        "id": "q6PAojH5ddpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "trainPredictd = deepmodel.predict(X_train)\n",
        "validPredictd = deepmodel.predict(X_valid)\n",
        "testPredictd = deepmodel.predict(X_test)\n",
        "# invert predictions\n",
        "trainPredictd = scaler.inverse_transform(trainPredictd)\n",
        "trainYd = scaler.inverse_transform(y_train)\n",
        "validPredictd = scaler.inverse_transform(validPredictd)\n",
        "validYd = scaler.inverse_transform(y_valid)\n",
        "testPredictd = scaler.inverse_transform(testPredictd)\n",
        "testYd = scaler.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "_1tNH6l4dqud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RMSE\n",
        "\n",
        "trainrmsed = mean_squared_error(trainYd, trainPredictd[:,0], squared = False)\n",
        "validrmsed = mean_squared_error(validYd, validPredictd[:,0], squared = False)\n",
        "testrmsed = mean_squared_error(testYd, testPredictd[:,0], squared = False)\n",
        "\n",
        "print(\"Train RMSE Deep\", trainrmsed)\n",
        "print(\"Valid RMSE Deep\", validrmsed)\n",
        "print(\"Test RMSE Deep\", testrmsed)\n"
      ],
      "metadata": {
        "id": "LnPdyENldsst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph TEST predicted vs actual DEEP RNN\n",
        "\n",
        "plt.plot(testPredictd, color = 'green', label = 'Predicted Close')\n",
        "plt.plot(testYd, color = 'blue', label = 'Original Close')\n",
        " \n",
        "plt.title('Deep RNN Stock Price Predictions on Test')\n",
        "plt.ylabel('Stock Price')\n",
        " \n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(15)\n",
        "fig.set_figheight(7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7aF3ASPHdqzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jDiCrVbsdvR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model 1"
      ],
      "metadata": {
        "id": "KGpLZTGAd56M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([\n",
        "    keras.layers.LSTM(20, return_sequences = True, input_shape = [None,1]),\n",
        "    keras.layers.LSTM(20),\n",
        "    keras.layers.Dense(1)                                      \n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam', loss='MeanSquaredError')\n",
        "history = model1.fit(X_train, y_train, epochs = 10, batch_size = 1, verbose =2)"
      ],
      "metadata": {
        "id": "UBUJ1fcBeB-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "trainPredictmod1 = model1.predict(X_train)\n",
        "validPredictmod1 = model1.predict(X_valid)\n",
        "testPredictmod1 = model1.predict(X_test)\n",
        "# invert predictions\n",
        "trainPredictmod1 = scaler.inverse_transform(trainPredictmod1)\n",
        "trainYmod1 = scaler.inverse_transform(y_train)\n",
        "validPredictmod1 = scaler.inverse_transform(validPredictmod1)\n",
        "validYmod1 = scaler.inverse_transform(y_valid)\n",
        "testPredictmod1 = scaler.inverse_transform(testPredictmod1)\n",
        "testYmod1 = scaler.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "WRujJKLReCB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RMSE LSTM MODEL 1\n",
        "\n",
        "trainrmsemod1 = mean_squared_error(trainYmod1, trainPredictmod1, squared = False)\n",
        "validrmsemod1 = mean_squared_error(validYmod1, validPredictmod1, squared = False)\n",
        "testrmsemod1 = mean_squared_error(testYmod1, testPredictmod1, squared = False)\n",
        "\n",
        "print(\"Train RMSE LSTM\", trainrmsemod1)\n",
        "print(\"Valid RMSE LSTM\", validrmsemod1)\n",
        "print(\"Test RMSE LSTM\", testrmsemod1)"
      ],
      "metadata": {
        "id": "1VhM4ixqeRP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph TEST predicted vs actual LSTM Model 1\n",
        "\n",
        "plt.plot(testPredictmod1, color = 'green', label = 'Predicted Close')\n",
        "plt.plot(testYmod1, color = 'blue', label = 'Original Close')\n",
        " \n",
        "plt.title('LSTM Model 1 Stock Price Predictions on Test')\n",
        "plt.ylabel('Stock Price')\n",
        " \n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(15)\n",
        "fig.set_figheight(7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Ijdb_DVeb_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8DAaXc6geRUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model 2: \n",
        "- Tuned with batch size and length of epochs\n",
        "- Training included monitoring validation loss"
      ],
      "metadata": {
        "id": "_j3Ioxk1ekAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my original model, I used ModelCheckpoint due to the larger number of epochs and have commented it out below. Instead of activating ModelCheckpoint, I will use the best model that was previously saved to calculate the performance."
      ],
      "metadata": {
        "id": "LnXwqZgWihND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = Sequential([\n",
        "    keras.layers.LSTM(20, return_sequences = True, input_shape = [None,1]),\n",
        "    keras.layers.LSTM(20),\n",
        "    keras.layers.Dense(1)                                      \n",
        "])\n",
        "\n",
        "model5.compile(optimizer='adam', loss='MeanSquaredError', metrics = [keras.metrics.MeanSquaredError()])\n",
        "\n",
        "#creating callback\n",
        "#filepath = '/content/drive/MyDrive/422NU/assign9/model5.epoch{epoch:03d}.h5'\n",
        "\n",
        "#checkpoint = ModelCheckpoint(filepath = filepath,\n",
        "#                             monitor='val_loss', verbose=1,\n",
        "#                             save_best_only = True,\n",
        "#                             mode = 'min')\n",
        "\n",
        "\n",
        "history = model5.fit(X_train, y_train, epochs = 50, batch_size = 4, verbose = 2, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "xQj7BS49e6jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5ld = load_model('/content/drive/MyDrive/422NU/assign9/model5.epoch047.h5')\n",
        "\n",
        "# make predictions LSTM4\n",
        "trainPredictmod5 = model5ld.predict(X_train)\n",
        "validPredictmod5 = model5ld.predict(X_valid)\n",
        "testPredictmod5 = model5ld.predict(X_test)\n",
        "# invert predictions\n",
        "trainPredictmod5 = scaler.inverse_transform(trainPredictmod5)\n",
        "trainYmod5 = scaler.inverse_transform(y_train)\n",
        "validPredictmod5 = scaler.inverse_transform(validPredictmod5)\n",
        "validYmod5 = scaler.inverse_transform(y_valid)\n",
        "testPredictmod5 = scaler.inverse_transform(testPredictmod5)\n",
        "testYmod5 = scaler.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "YTHoHpj_iemK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RMSE LSTM MODEL 2\n",
        "\n",
        "trainrmsemod5 = mean_squared_error(trainYmod5, trainPredictmod5, squared = False)\n",
        "validrmsemod5 = mean_squared_error(validYmod5, validPredictmod5, squared = False)\n",
        "testrmsemod5 = mean_squared_error(testYmod5, testPredictmod5, squared = False)\n",
        "\n",
        "print(\"Train RMSE LSTM 5\", trainrmsemod5)\n",
        "print(\"Valid RMSE LSTM 5\", validrmsemod5)\n",
        "print(\"Test RMSE LSTM 5\", testrmsemod5)"
      ],
      "metadata": {
        "id": "KWByQJDzjJtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph TEST predicted vs actual LSTM Model 2\n",
        "\n",
        "plt.plot(testPredictmod5, color = 'green', label = 'Predicted Close')\n",
        "plt.plot(testYmod5, color = 'blue', label = 'Original Close')\n",
        " \n",
        "plt.title('LSTM Model 2 Stock Price Predictions on Test')\n",
        "plt.ylabel('Stock Price')\n",
        " \n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(15)\n",
        "fig.set_figheight(7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tQdgeVG_jPJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "rAioMlVZjUic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Deep RNN Model performed best with 10 epochs achieving an RMSE of 23.65 on the Test set. \n",
        "LSTM Model 2 performed slightly worse, achieving an RMSE of 26.46 on the Test set. Including the validation data during training helped to mitigate overfitting, since the RMSE of the Validation set was higher than that of the Test set due to the price volatility at that time."
      ],
      "metadata": {
        "id": "zPW6aWaqjWzD"
      }
    }
  ]
}